{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\catra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('songs.json', 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'songName': 'Hurt',\n",
       " 'spotifyLink': 'https://open.spotify.com/track/1lo9k4PrxFd5Np4cAxXoKo?si=881892db7eaa4a71',\n",
       " 'genre': 'Rock',\n",
       " 'lyrics': \"I hurt myself today\\nTo see if I still feel\\nI focus on the pain\\nThe only thing that's real\\nThe needle tears a hole\\nThe old familiar sting\\nTry to kill it all away\\nBut I remember everything\\nWhat have I become?\\nMy sweetest friend\\nEveryone I know goes away\\nIn the end\\nAnd you could have it all\\nMy empire of dirt\\nI will let you down\\nI will make you hurt\\nI wear this crown of thorns\\nUpon my liar's chair\\nFull of broken thoughts\\nI cannot repair\\nBeneath the stains of time\\nThe feelings disappear\\nYou are someone else\\nI'm still right here\\nWhat have I become?\\nMy sweetest friend\\nEveryone I know goes away\\nIn the end\\nAnd you could have it all\\nMy empire of dirt\\nI will let you down\\nI will make you hurt\\nIf I could start again\\nA million miles away\\nI would keep myself\\nI would find a way\",\n",
       " 'mood': '100stress'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert prediction to value\n",
    "\n",
    "def pred_to_mh(pred):\n",
    "    label_mapping = {\n",
    "        0: \"Stressed\",\n",
    "        1: \"Depressed\",\n",
    "        2: \"Neutral\",\n",
    "        3: \"Happy\",\n",
    "        4: \"Studious\"\n",
    "    }\n",
    "\n",
    "    return label_mapping[pred]\n",
    "\n",
    "result = pred_to_mh(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Depressed'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = {\n",
    "    \"Stressed\": \n",
    "        [\"stress\", \"uneasy\", \"nervous\", \"discomfort\", \"inconvenient\", \"Anxious\", \"Exhausting\", \"Intense\", \n",
    "         \"Panic\", \"Unmanageable\", \"Breakdown\"],\n",
    "    \n",
    "    \"Depressed\":\n",
    "        [\"Melancholic\", \"Somber\", \"Blue\", \"Gloomy, depression\", \"rain\", \"Overwhelming\", \"Desperate\", \n",
    "         \"Suicidal\", \"Paralyzed\", \"Incapacitating\", \"Unbearable\", \"Devastated\", \"cry\", \"tears\", \"pain\"],\n",
    "    \n",
    "    \"Neutral\":\n",
    "        [\"bored\", \"simple\", \"pleasant\", \"normal\", \"neutral\"],\n",
    "        \n",
    "    \"Happy\":\n",
    "        [\"Stable\", \"Calm\", \"Satisfied\", \"Happy\", \"Content\", \"Manic\", \"Euphoric\", \"Ecstatic\", \"Party\",\n",
    "         \"Dance\", \"excited\"],\n",
    "        \n",
    "    \"Studious\":\n",
    "        [\"smart\", \"study\", \"brain\", \"school\", \"grades\", \"graduation\", \"homework\", \"scholar\", \"work\",\n",
    "         \"writing\", \"teacher\", \"students\", \"reading\", \"intelligent\", \"education\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hurt today see still feel focus pain thing real needle tears hole old familiar sting try kill away remember everything become sweetest friend everyone know goes away end could empire dirt make hurt wear crown thorns upon liars chair full broken thoughts cannot repair beneath stains time feelings disappear someone else still right become sweetest friend everyone know goes away end could empire dirt make hurt could start million miles away would keep would find way',\n",
       " 'wasted times spent someone else wasnt even half reminiscin felt niscin felt even though life hell seem forget want belong give love pullin gettin sprung aint cause lot dont make run blowin spot cause aint business catchin feelings anyway aint business catchin feelings catchin feelings girls want youre winnin winnin youve beginnin ooh yeah yeah know right talkin talkin hope know dick still option cause ill beat ill beat yeah took time learn way body functions equestrian ride like champion ride baby sex get high without substance belong belong give love give love pullin gettin sprung gettin sprung aint cause lot lot dont make run blowin spot blowin spot cause aint business catchin feelings anyway aint business catchin feelings feelings catchin feelings aint business catchin feelings aint business catchin feelings catchin feefeefeefee feelings aint business catchin feelings aint business catchin feelings catchin feefeefeefee wake dont wanna wake dont wanna wake aint layin next dont wanna wake dont wanna wake dont wanna wake aint layin next meee oh',\n",
       " 'ohh anybody see war fight never found way regardless feel wrong moment feel wrong storm morning light feel frozen nobody side surely aint right surely aint right ohh anybody see war fight never found way regardless feel wrong moment feel wrong feel wrong moment feel wrong ohh anybody see war fight never found way regardless feel wrong moment feel wrong',\n",
       " 'confusion eyes says shes lost control shes clinging nearest passerby shes lost control gave away secrets past said ive lost control voice told act said ive lost control turned around took hand said ive lost control ill never know understand said ive lost control screamed kicking side said ive lost control seized floor thought shed die said ive lost control shes lost control shes lost control shes lost control shes lost control phone friend state case shes lost control showed errors mistakes said ive lost control expressed many different ways lost control walked upon edge escape laughed ive lost control shes lost control shes lost control shes lost control shes lost control',\n",
       " 'aint sunshine shes gone warm shes away aint sunshine shes gone shes always gone long anytime shes goes away wonder time shes gone wonder shes gone stay aint sunshine shes gone house aint home anytime goes away know know know know know know know know know know know know know know know know know know know know know know know know know know hey oughta leave young thing alone aint sunshine shes gone woh woh aint sunshine shes gone darkness every day aint sunshine shes gone house aint home anytime goes away anytime goes away anytime goes away anytime goes away',\n",
       " 'angie angie dark clouds disappear angie angie lead us lovin souls money coats satisfied angie angie never tried angie youre beautiful aint time goodbye angie still love remember nights cried dreams held close seemed go smoke whisper ear angie angie lead us oh angie dont wish oh kisses still taste sweet hate sadness eyes angie angie aint time said goodbye lovin souls money coats satisfied angie still love baby everywhere look see eyes aint woman comes close come baby dry eyes angie angie aint good alive angie angie never tried',\n",
       " 'perfect picture head beautiful dress look happy ever go standing alone rain like kinda movie used hate wish could take back time know time real hate singing song hate strong hate youre gone hate flaws hate love someone else hate everything hate everything right doubts thought could work gave needed promised forever forever dont last long standing alone rain like kinda movie used hate wish could take back time know time real hate singing song hate strong hate youre gone hate flaws hate love someone else hate everything hate everything right really wish way erase beautiful memories killing oh baby hate singing song hate strong hate youre gone hate flaws hate love someone else hate everything hate everything right hate everything hate everything right']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean (remove stopwords and whatnot)\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "list_of_words = word_list[result]\n",
    "list_of_song_lyrics = [song_record[\"lyrics\"] for song_record in data]\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.update({'im', 'em', 'on', 'say', 'cant', 'bout', 'about', \n",
    "                   'that', 'thats', 'put', 'askin', 'weve', 'got', 'could'\n",
    "                   'would', 'let'})\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text_without_newlines = text.replace(\"\\n\", \" \")\n",
    "    words = text_without_newlines.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def clean_all(list):    \n",
    "    cleaned_lists = []\n",
    "    for text in list:\n",
    "        filtered_text_list = text.lower()\n",
    "        filtered_text_list = re.sub(r'[^\\w\\s]', '', filtered_text_list)\n",
    "        filtered_text_list = remove_stopwords(filtered_text_list)\n",
    "        cleaned_lists.append(filtered_text_list)\n",
    "    return cleaned_lists\n",
    "\n",
    "list_of_song_lyrics = clean_all(list_of_song_lyrics)\n",
    "list_of_song_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['melancholic',\n",
       " 'somber',\n",
       " 'blue',\n",
       " 'gloomy depression',\n",
       " 'rain',\n",
       " 'overwhelming',\n",
       " 'desperate',\n",
       " 'suicidal',\n",
       " 'paralyzed',\n",
       " 'incapacitating',\n",
       " 'unbearable',\n",
       " 'devastated',\n",
       " 'cry',\n",
       " 'tears',\n",
       " 'pain']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def embed_text(list_of_lists):\n",
    "    encoded_texts = []\n",
    "\n",
    "    for sublist in list_of_lists:\n",
    "        encoded_sublist = []\n",
    "\n",
    "        for text in sublist:\n",
    "            encoded_text = tokenizer(text, padding=True, truncation=True, return_tensors='tf')\n",
    "            encoded_sublist.append(encoded_text)\n",
    "\n",
    "        encoded_texts.append(encoded_sublist)\n",
    "\n",
    "    word_index = tokenizer.get_vocab()\n",
    "    return encoded_texts, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_list_of_song_lyrics, song_word_index = embed_text(list_of_song_lyrics)\n",
    "embeded_list_of_words, words_word_index = embed_text(list_of_song_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\numpy\\core\\_methods.py:164: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asanyarray(a)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\catra\\OneDrive\\Documents\\Repos\\dubhacks_23\\music\\music_search.ipynb Cell 11\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Assuming you have word embeddings for your words and songs\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Replace these with your actual word embeddings and song embeddings\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# list_of_words_embeddings = np.array([word_embed(word) for word in list_of_words])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# song_lyrics_embeddings = [np.array([word_embed(word) for word in song_lyrics]) for song_lyrics in list_of_song_lyrics]\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m list_avg_embedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmean(embeded_list_of_song_lyrics, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# similarities = [cosine_similarity([list_avg_embedding], [song_embedding])[0][0] for song_embedding in song_lyrics_embeddings]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# best_match_index = np.argmax(similarities)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/music/music_search.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# best_matching_song\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3429\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3430\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 3432\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_mean(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   3433\u001b[0m                       out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\numpy\\core\\_methods.py:192\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    190\u001b[0m         ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype(ret \u001b[39m/\u001b[39m rcount)\n\u001b[0;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     ret \u001b[39m=\u001b[39m ret \u001b[39m/\u001b[39;49m rcount\n\u001b[0;32m    194\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming you have word embeddings for your words and songs\n",
    "# Replace these with your actual word embeddings and song embeddings\n",
    "# list_of_words_embeddings = np.array([word_embed(word) for word in list_of_words])\n",
    "# song_lyrics_embeddings = [np.array([word_embed(word) for word in song_lyrics]) for song_lyrics in list_of_song_lyrics]\n",
    "\n",
    "list_avg_embedding = np.mean(embeded_list_of_song_lyrics, axis=0)\n",
    "\n",
    "similarities = [cosine_similarity([list_avg_embedding], [song_embedding])[0][0] for song_embedding in song_lyrics_embeddings]\n",
    "\n",
    "best_match_index = np.argmax(similarities)\n",
    "\n",
    "best_matching_song = data[best_match_index]['songName']\n",
    "\n",
    "best_matching_song"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainwave_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
