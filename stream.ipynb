{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylsl import StreamInlet, resolve_byprop\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import pickle\n",
    "from itertools import chain\n",
    "\n",
    "BUFFER_LENGTH = 5\n",
    "EPOCH_LENGTH = 1\n",
    "OVERLAP_LENGTH = 0\n",
    "SHIFT_LENGTH = EPOCH_LENGTH - OVERLAP_LENGTH\n",
    "INDEX_CHANNEL = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "with open('model_building/eeg_to_mh_state.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('music/songs.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_song_lyrics = [song_record[\"lyrics\"] for song_record in data]\n",
    "list_of_song_lyrics = clean_all(list_of_song_lyrics)\n",
    "\n",
    "list_of_words = clean_all(list(chain(*word_list.values())))\n",
    "\n",
    "corpus = build_corpus(list_of_words, list_of_song_lyrics)\n",
    "\n",
    "sentences = [word.split() for word in corpus]\n",
    "\n",
    "modelw2v = word2vec.Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "modelw2v.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for an EEG stream...\n",
      "Found it!\n",
      "[<pylsl.pylsl.StreamInfo object at 0x000001CBE8EB8FA0>]\n",
      "Start acquiring data\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\catra\\OneDrive\\Documents\\Repos\\dubhacks_23\\stream.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m band_buffer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n_win_test, \u001b[39m4\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m# Obtain EEG data from the LSL stream\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     eeg_data, timestamp \u001b[39m=\u001b[39m inlet\u001b[39m.\u001b[39;49mpull_chunk(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, max_samples\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(SHIFT_LENGTH \u001b[39m*\u001b[39;49m fs))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# Only keep the channel we're interested in\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     ch_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(eeg_data)[:, INDEX_CHANNEL]\n",
      "File \u001b[1;32mc:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\pylsl\\pylsl.py:857\u001b[0m, in \u001b[0;36mStreamInlet.pull_chunk\u001b[1;34m(self, timeout, max_samples, dest_obj)\u001b[0m\n\u001b[0;32m    855\u001b[0m errcode \u001b[39m=\u001b[39m c_int()\n\u001b[0;32m    856\u001b[0m \u001b[39m# noinspection PyCallingNonCallable\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m num_elements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_pull_chunk(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj, byref(data_buff),\n\u001b[0;32m    858\u001b[0m                                   byref(ts_buff), c_size_t(max_values),\n\u001b[0;32m    859\u001b[0m                                   c_size_t(max_samples), c_double(timeout),\n\u001b[0;32m    860\u001b[0m                                   byref(errcode))\n\u001b[0;32m    861\u001b[0m handle_error(errcode)\n\u001b[0;32m    862\u001b[0m \u001b[39m# return results (note: could offer a more efficient format in the\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39m# future, e.g., a numpy array)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Search for active LSL streams\n",
    "print('Looking for an EEG stream...')\n",
    "streams = resolve_byprop('type', 'EEG', timeout=2)\n",
    "if len(streams) == 0:\n",
    "    raise RuntimeError('Can\\'t find EEG stream.')\n",
    "else:\n",
    "    print('Found it!')\n",
    "    print(streams)\n",
    "    \n",
    "# Set active EEG stream to inlet and apply time correction\n",
    "print(\"Start acquiring data\")\n",
    "inlet = StreamInlet(streams[0], max_chunklen=12)\n",
    "eeg_time_correction = inlet.time_correction()\n",
    "\n",
    "# Get the stream info\n",
    "info = inlet.info()\n",
    "fs = int(info.nominal_srate())\n",
    "\n",
    "# Initialize raw EEG data buffer\n",
    "eeg_buffer = np.zeros((int(fs * BUFFER_LENGTH), 1))\n",
    "filter_state = None  # for use with the notch filter\n",
    "\n",
    "# Compute the number of epochs in \"buffer_length\"\n",
    "n_win_test = int(np.floor((BUFFER_LENGTH - EPOCH_LENGTH) /\n",
    "                            SHIFT_LENGTH + 1))\n",
    "\n",
    "# Initialize the band power buffer (for plotting)\n",
    "# bands will be ordered: [delta, theta, alpha, beta]\n",
    "band_buffer = np.zeros((n_win_test, 4))\n",
    "\n",
    "while True:\n",
    "    # Obtain EEG data from the LSL stream\n",
    "    eeg_data, timestamp = inlet.pull_chunk(\n",
    "        timeout=1, max_samples=int(SHIFT_LENGTH * fs))\n",
    "\n",
    "    # Only keep the channel we're interested in\n",
    "    ch_data = np.array(eeg_data)[:, INDEX_CHANNEL]\n",
    "\n",
    "    # Update EEG buffer with the new data\n",
    "    eeg_buffer, filter_state = update_buffer(\n",
    "        eeg_buffer, ch_data, notch=True,\n",
    "        filter_state=filter_state)\n",
    "\n",
    "    # Get newest samples from the buffer\n",
    "    data_epoch = get_last_data(eeg_buffer,\n",
    "                                        EPOCH_LENGTH * fs)\n",
    "\n",
    "    # Compute band powers\n",
    "    band_powers = compute_band_powers(data_epoch, fs)\n",
    "    band_buffer, _ = update_buffer(band_buffer,\n",
    "                                            np.asarray([band_powers]))\n",
    "    bw_data = {\n",
    "    'Delta': [band_powers[0]],\n",
    "    'Theta': [band_powers[1]],\n",
    "    'Alpha': [band_powers[2]],\n",
    "    'Beta': [band_powers[3]]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(bw_data)\n",
    "    \n",
    "    pred = model.predict(df)\n",
    "    result = pred_to_mh(pred[0])\n",
    "\n",
    "    print(f'prediction: {result}')\n",
    "    \n",
    "    list_of_words = word_list[result]\n",
    "    filtered_data = filter_songs(str(result).lower(), data)\n",
    "    list_of_song_lyrics = [song_record[\"lyrics\"] for song_record in filtered_data]\n",
    "    \n",
    "    list_of_song_lyrics = clean_all(list_of_song_lyrics)\n",
    "    list_of_words = clean_all(list_of_words)\n",
    "\n",
    "    best_matching_song, similarities = get_song(list_of_words, list_of_song_lyrics, filtered_data, modelw2v)\n",
    "    print(f'song: {best_matching_song}')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainwave_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
