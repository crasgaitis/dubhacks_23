{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylsl import StreamInlet, resolve_byprop\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import pickle\n",
    "from itertools import chain\n",
    "\n",
    "BUFFER_LENGTH = 5\n",
    "EPOCH_LENGTH = 1\n",
    "OVERLAP_LENGTH = 0\n",
    "SHIFT_LENGTH = EPOCH_LENGTH - OVERLAP_LENGTH\n",
    "INDEX_CHANNEL = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "with open('model_building/eeg_to_mh_state.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('music/songs.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_song_lyrics = [song_record[\"lyrics\"] for song_record in data]\n",
    "list_of_song_lyrics = clean_all(list_of_song_lyrics)\n",
    "\n",
    "list_of_words = clean_all(list(chain(*word_list.values())))\n",
    "\n",
    "corpus = build_corpus(list_of_words, list_of_song_lyrics)\n",
    "\n",
    "sentences = [word.split() for word in corpus]\n",
    "\n",
    "modelw2v = word2vec.Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "modelw2v.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for an EEG stream...\n",
      "Found it!\n",
      "[<pylsl.pylsl.StreamInfo object at 0x000001CBE8EB8FA0>]\n",
      "Start acquiring data\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n",
      "prediction: Happy\n",
      "song: Happy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\catra\\OneDrive\\Documents\\Repos\\dubhacks_23\\stream.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m band_buffer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n_win_test, \u001b[39m4\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m# Obtain EEG data from the LSL stream\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     eeg_data, timestamp \u001b[39m=\u001b[39m inlet\u001b[39m.\u001b[39;49mpull_chunk(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, max_samples\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(SHIFT_LENGTH \u001b[39m*\u001b[39;49m fs))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# Only keep the channel we're interested in\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     ch_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(eeg_data)[:, INDEX_CHANNEL]\n",
      "File \u001b[1;32mc:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\pylsl\\pylsl.py:857\u001b[0m, in \u001b[0;36mStreamInlet.pull_chunk\u001b[1;34m(self, timeout, max_samples, dest_obj)\u001b[0m\n\u001b[0;32m    855\u001b[0m errcode \u001b[39m=\u001b[39m c_int()\n\u001b[0;32m    856\u001b[0m \u001b[39m# noinspection PyCallingNonCallable\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m num_elements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_pull_chunk(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj, byref(data_buff),\n\u001b[0;32m    858\u001b[0m                                   byref(ts_buff), c_size_t(max_values),\n\u001b[0;32m    859\u001b[0m                                   c_size_t(max_samples), c_double(timeout),\n\u001b[0;32m    860\u001b[0m                                   byref(errcode))\n\u001b[0;32m    861\u001b[0m handle_error(errcode)\n\u001b[0;32m    862\u001b[0m \u001b[39m# return results (note: could offer a more efficient format in the\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39m# future, e.g., a numpy array)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Search for active LSL streams\n",
    "print('Looking for an EEG stream...')\n",
    "streams = resolve_byprop('type', 'EEG', timeout=2)\n",
    "if len(streams) == 0:\n",
    "    raise RuntimeError('Can\\'t find EEG stream.')\n",
    "else:\n",
    "    print('Found it!')\n",
    "    print(streams)\n",
    "    \n",
    "# Set active EEG stream to inlet and apply time correction\n",
    "print(\"Start acquiring data\")\n",
    "inlet = StreamInlet(streams[0], max_chunklen=12)\n",
    "eeg_time_correction = inlet.time_correction()\n",
    "\n",
    "# Get the stream info\n",
    "info = inlet.info()\n",
    "fs = int(info.nominal_srate())\n",
    "\n",
    "# Initialize raw EEG data buffer\n",
    "eeg_buffer = np.zeros((int(fs * BUFFER_LENGTH), 1))\n",
    "filter_state = None  # for use with the notch filter\n",
    "\n",
    "# Compute the number of epochs in \"buffer_length\"\n",
    "n_win_test = int(np.floor((BUFFER_LENGTH - EPOCH_LENGTH) /\n",
    "                            SHIFT_LENGTH + 1))\n",
    "\n",
    "# Initialize the band power buffer (for plotting)\n",
    "# bands will be ordered: [delta, theta, alpha, beta]\n",
    "band_buffer = np.zeros((n_win_test, 4))\n",
    "\n",
    "while True:\n",
    "    # Obtain EEG data from the LSL stream\n",
    "    eeg_data, timestamp = inlet.pull_chunk(\n",
    "        timeout=1, max_samples=int(SHIFT_LENGTH * fs))\n",
    "\n",
    "    # Only keep the channel we're interested in\n",
    "    ch_data = np.array(eeg_data)[:, INDEX_CHANNEL]\n",
    "\n",
    "    # Update EEG buffer with the new data\n",
    "    eeg_buffer, filter_state = update_buffer(\n",
    "        eeg_buffer, ch_data, notch=True,\n",
    "        filter_state=filter_state)\n",
    "\n",
    "    # Get newest samples from the buffer\n",
    "    data_epoch = get_last_data(eeg_buffer,\n",
    "                                        EPOCH_LENGTH * fs)\n",
    "\n",
    "    # Compute band powers\n",
    "    band_powers = compute_band_powers(data_epoch, fs)\n",
    "    band_buffer, _ = update_buffer(band_buffer,\n",
    "                                            np.asarray([band_powers]))\n",
    "    bw_data = {\n",
    "    'Delta': [band_powers[0]],\n",
    "    'Theta': [band_powers[1]],\n",
    "    'Alpha': [band_powers[2]],\n",
    "    'Beta': [band_powers[3]]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(bw_data)\n",
    "    \n",
    "    pred = model.predict(df)\n",
    "    result = pred_to_mh(pred[0])\n",
    "\n",
    "    print(f'prediction: {result}')\n",
    "    \n",
    "    list_of_words = word_list[result]\n",
    "    filtered_data = filter_songs(str(result).lower(), data)\n",
    "    list_of_song_lyrics = [song_record[\"lyrics\"] for song_record in filtered_data]\n",
    "    \n",
    "    list_of_song_lyrics = clean_all(list_of_song_lyrics)\n",
    "    list_of_words = clean_all(list_of_words)\n",
    "\n",
    "    best_matching_song, similarities = get_song(list_of_words, list_of_song_lyrics, filtered_data, modelw2v)\n",
    "    print(f'song: {best_matching_song}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[nan].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\catra\\OneDrive\\Documents\\Repos\\dubhacks_23\\stream.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     best_matching_song \u001b[39m=\u001b[39m data[best_match_index][\u001b[39m'\u001b[39m\u001b[39msongName\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_matching_song, similarities\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m best_matching_song, similarities \u001b[39m=\u001b[39m get_song(list_of_words, list_of_song_lyrics, filtered_data, modelw2v)\n",
      "\u001b[1;32mc:\\Users\\catra\\OneDrive\\Documents\\Repos\\dubhacks_23\\stream.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m list_avg_embedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(song_lyrics_embeddings, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(list_avg_embedding)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m similarities \u001b[39m=\u001b[39m [cosine_similarity([list_avg_embedding], [word_embedding][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m word_embedding \u001b[39min\u001b[39;00m list_of_words_embeddings]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m best_match_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(similarities)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m best_matching_song \u001b[39m=\u001b[39m data[best_match_index][\u001b[39m'\u001b[39m\u001b[39msongName\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\catra\\OneDrive\\Documents\\Repos\\dubhacks_23\\stream.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m list_avg_embedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(song_lyrics_embeddings, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(list_avg_embedding)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m similarities \u001b[39m=\u001b[39m [cosine_similarity([list_avg_embedding], [word_embedding][\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]) \u001b[39mfor\u001b[39;00m word_embedding \u001b[39min\u001b[39;00m list_of_words_embeddings]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m best_match_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(similarities)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/catra/OneDrive/Documents/Repos/dubhacks_23/stream.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m best_matching_song \u001b[39m=\u001b[39m data[best_match_index][\u001b[39m'\u001b[39m\u001b[39msongName\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1393\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m \n\u001b[0;32m   1360\u001b[0m \u001b[39mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[39m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[39m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1393\u001b[0m X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m   1395\u001b[0m X_normalized \u001b[39m=\u001b[39m normalize(X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:155\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m     X \u001b[39m=\u001b[39m Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    147\u001b[0m         X,\n\u001b[0;32m    148\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    153\u001b[0m     )\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    156\u001b[0m         X,\n\u001b[0;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    158\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    159\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    160\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    164\u001b[0m         Y,\n\u001b[0;32m    165\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32mc:\\Users\\catra\\anaconda3\\envs\\brainwave_project\\lib\\site-packages\\sklearn\\utils\\validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    907\u001b[0m         )\n\u001b[0;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[nan].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "def get_song(list_of_words, list_of_song_lyrics, data, model):\n",
    "    list_of_words_embeddings = word_embed(list_of_words, model)\n",
    "    song_lyrics_embeddings = word_embed(list_of_song_lyrics, model)\n",
    "\n",
    "\n",
    "    print(song_lyrics_embeddings)\n",
    "    list_avg_embedding = np.mean(song_lyrics_embeddings, axis=0)\n",
    "    \n",
    "    print(list_avg_embedding)\n",
    "\n",
    "    similarities = [cosine_similarity([list_avg_embedding], [word_embedding][0][0]) for word_embedding in list_of_words_embeddings]\n",
    "\n",
    "    best_match_index = np.argmax(similarities)\n",
    "\n",
    "    best_matching_song = data[best_match_index]['songName']\n",
    "\n",
    "    return best_matching_song, similarities\n",
    "\n",
    "best_matching_song, similarities = get_song(list_of_words, list_of_song_lyrics, filtered_data, modelw2v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainwave_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
