{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy.csv data saved to preprocessed_data\\happy.csv_preprocessed_data.csv\n",
      "happy2.csv data saved to preprocessed_data\\happy2.csv_preprocessed_data.csv\n",
      "happy3.csv data saved to preprocessed_data\\happy3.csv_preprocessed_data.csv\n",
      "happy4.csv data saved to preprocessed_data\\happy4.csv_preprocessed_data.csv\n",
      "happy5.csv data saved to preprocessed_data\\happy5.csv_preprocessed_data.csv\n",
      "happy6.csv data saved to preprocessed_data\\happy6.csv_preprocessed_data.csv\n",
      "study.csv data saved to preprocessed_data\\study.csv_preprocessed_data.csv\n",
      "study10.csv data saved to preprocessed_data\\study10.csv_preprocessed_data.csv\n",
      "study11.csv data saved to preprocessed_data\\study11.csv_preprocessed_data.csv\n",
      "study12.csv data saved to preprocessed_data\\study12.csv_preprocessed_data.csv\n",
      "study13.csv data saved to preprocessed_data\\study13.csv_preprocessed_data.csv\n",
      "study14.csv data saved to preprocessed_data\\study14.csv_preprocessed_data.csv\n",
      "study2.csv data saved to preprocessed_data\\study2.csv_preprocessed_data.csv\n",
      "study3.csv data saved to preprocessed_data\\study3.csv_preprocessed_data.csv\n",
      "study4.csv data saved to preprocessed_data\\study4.csv_preprocessed_data.csv\n",
      "study5.csv data saved to preprocessed_data\\study5.csv_preprocessed_data.csv\n",
      "study6.csv data saved to preprocessed_data\\study6.csv_preprocessed_data.csv\n",
      "study7.csv data saved to preprocessed_data\\study7.csv_preprocessed_data.csv\n",
      "study8.csv data saved to preprocessed_data\\study8.csv_preprocessed_data.csv\n",
      "study9.csv data saved to preprocessed_data\\study9.csv_preprocessed_data.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def compute_average(group_name, df):\n",
    "    group_columns = [col for col in df.columns if group_name in col]\n",
    "    return df[group_columns].mean(axis=1)\n",
    "\n",
    "def consolidate(freq_min, freq_max, brainwave, userdf, df_temp):\n",
    "    \n",
    "    pattern = re.compile(rf\".*[{freq_min}-{freq_max}]Hz.*\")\n",
    "    columns_to_include = [col for col in userdf.columns if re.match(pattern, col)]\n",
    "\n",
    "    bw_average = userdf[columns_to_include].mean(axis=1)\n",
    "    bw_median = np.array([np.median(bw_average)])\n",
    "\n",
    "    df_temp[f\"{brainwave}\"] = bw_median\n",
    "    \n",
    "    df_temp = pd.DataFrame()\n",
    "    \n",
    "folder_path = \"data_samples\"\n",
    "\n",
    "mega_df = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Load the CSV file into a DataFrame\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        brain_data = pd.read_csv(file_path)\n",
    "\n",
    "    df_temp = pd.DataFrame()\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    pattern = re.compile(\"^Aux|^f_\")\n",
    "    unwanted = [col for col in brain_data.columns if re.match(pattern, col)]\n",
    "    userdf = brain_data.drop(columns=unwanted)\n",
    "    userdf = userdf.drop('info', axis=1)\n",
    "\n",
    "    consolidate(1, 3, \"Delta\", userdf, df_temp)\n",
    "    consolidate(4, 7, \"Theta\", userdf, df_temp)\n",
    "    consolidate(8, 9, \"Alpha1\", userdf, df_temp)\n",
    "    consolidate(10, 11, \"Alpha2\", userdf, df_temp)\n",
    "    consolidate(12, 20, \"Beta1\", userdf, df_temp)\n",
    "    consolidate(20, 29, \"Beta2\", userdf, df_temp)\n",
    "\n",
    "    # combine alpha1 + alpha2, and beta1 + beta2\n",
    "    groups = ['Alpha', 'Beta']\n",
    "    for group in groups:\n",
    "        df_temp[f'{group}'] = compute_average(group, df_temp)\n",
    "\n",
    "    userdf = df_temp\n",
    "    userdf = userdf.drop(columns=['Alpha1', 'Alpha2', 'Beta1', 'Beta2'])\n",
    "    \n",
    "    output_file = os.path.join(\"preprocessed_data\", f\"{filename}_preprocessed_data.csv\")\n",
    "    userdf.to_csv(output_file, index=False)\n",
    "    print(f\"{filename} data saved to {output_file}\")\n",
    "\n",
    "# combine to mega csv\n",
    "for filename in os.listdir(\"preprocessed_data\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Load each CSV file into a DataFrame\n",
    "        file_path = os.path.join(\"preprocessed_data\", filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if 'happy' in filename:\n",
    "            # Set 'specific.disorder' to 'happy'\n",
    "            df['specific.disorder'] = 'happy'\n",
    "        else:\n",
    "            # Set 'specific.disorder' to 'studious'\n",
    "            df['specific.disorder'] = 'studious'        \n",
    "        \n",
    "        # Concatenate the current DataFrame to the mega DataFrame\n",
    "        mega_df = pd.concat([mega_df, df], ignore_index=True)\n",
    "\n",
    "mega_df.to_csv(\"mega_preprocessed_data.csv\", index=False)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainwave_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
